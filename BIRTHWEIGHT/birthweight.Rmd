---
title: "Birthweight"
author: "Tommaso Rigon and Emanuele Aliverti"
output: html_document
bibliography: ["../biblio.bib"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Birthweight Study

*(This tutorial illustrates main results of the analysis in an easy-to-read format.
Complete code associated with this page is available in the file* 
[birthweight.Rmd](https://raw.githubusercontent.com/tommasorigon/logistic-bias-reduction/main/BIRTHWEIGHT/birthweight.Rmd)),

This tutorial is devoted to replicating simulations from @Kosmidis2020, available in Table 2 of the article
Data comprises $n = 100$ births and the binary outcome of interest is a dichotomization of 
infant birthweight (low against normal). 

```{r load, echo=F,warning=FALSE,message=F}
## Replicate simulations from Kosmidis et al (2020) <doi:10.1007/s11222-019-09860-6
rm(list = ls())
library(brglm2)
library(detectseparation)
library(knitr)
```

```{r clean, echo=T,warning=FALSE,message=F}
library(MASS)
## PREPARE THE DATASET
bwt <- with(birthwt, {
  age <- age
  racewhite <- ifelse(race == 1, 1, 0)
  smoke <- smoke
  ptl <- ifelse(ptl > 0, 1, 0)
  ptd <- factor(ptl > 0)
  ht <- ht
  loglwt <- log(lwt)
  data.frame(normwt = 1 - low, age, racewhite, smoke, ptl, ht, loglwt, ftv)
})
bwt <- subset(bwt, subset = (ftv == 0), select = -c(ftv))
```

A logistic regression is employed with covariates pertaining the mother, namely: age, race, smoking habitudes, history of premature labour and hypertension and
the logarithm of the weight at birth of the mother.

Similarly to the `endometrial` [case study](../ENDOMETRIAL/), we compare the proposed
Diaconis-Ylvisaker regularization with @Clogg1991, @Firth1993 and @Pagui2017, relying on the package `brglm2` [@Kosmidis2021].

```{r,echo=T,warning=FALSE}
## ESTIMATES
X <- model.matrix(normwt ~ age + racewhite + smoke + ptl + ht + loglwt, data = bwt)
p <- ncol(X)
n <- m <- nrow(X)

# MLE
ml_fit <- glm(normwt ~ age + racewhite + smoke + ptl + ht + loglwt, family = binomial, data = bwt)

# DY
y_dy <- p / (p + m) * 0.5 + m / (p + m) * bwt$normwt
dy_fit <- glm(y_dy ~ age + racewhite + smoke + ptl + ht + loglwt, family = binomial, data = bwt)

# CLOGG ET AL. (1991)
ybar <- mean(bwt$normwt)
y_clogg <- p / (p + m) * ybar + m / (p + m) * bwt$normwt
clogg_fit <- glm(y_clogg ~ age + racewhite + smoke + ptl + ht + loglwt, family = binomial, data = bwt)

# FIRTH (1993)
br_fit <- update(ml_fit, method = "brglmFit", type = "AS_mean", data = bwt)

# KENNE PAGUI ET AL. (2017)
mbr_fit <- update(ml_fit, method = "brglmFit", type = "AS_median", data = bwt)
```

Estimated regression coefficients are reported in the following table. Note that maximum-likelihood estimate
exists finite in this example.

```{r,echo=F,warning=FALSE}
se = function(x) summary(x)$coef[,"Std. Error"]
estimates <- rbind(coef(ml_fit), coef(dy_fit), coef(clogg_fit), coef(br_fit), coef(mbr_fit))
std_errors <- rbind(se(ml_fit), se(dy_fit), se(clogg_fit), se(br_fit), se(mbr_fit))

results_table = matrix(paste0(round(estimates,2)," (", round(std_errors,2),")"),ncol = p)

row.names(results_table) = c("MLE", "Diaconis-Ylvisaker","@Clogg1991", "@Firth1993", "@Pagui2017")
kable(results_table, digits = 3,format = "markdown", caption = "MLE and BR estimates")
```

We assess the properties of different approaches relying on a simulation study.
Specifically, $10000$ artificial datasets are generated from the maximum-likelihood estimates.
The approaches illustrated on Table 1 are estimated for each replications, and we evaluate their
performance in terms of bias and root mean squared error.
Note that the simulation requires roughly $3$ minutes on a 2020 Macbook Pro with M1 processor 
(`aarch64-apple-darwin20`)  running R 4.1.1 linked with `openblas`. 

```{r simulation,echo=F, eval=F, cache=T,warning=F}
# SIMULATION STUDY ON 10.000 REPLICATES

## Select a seed
set.seed(1991)

## Simulated response variable
Nsim <- 10000
simdata <- simulate(ml_fit, nsim = Nsim)
beta <- coef(ml_fit)

ml <- br <- mbr <- clogg <- dy <- ml_se <- br_se <- clogg_se <- mbr_se <- dy_se <- separation <- matrix(NA, nrow = Nsim, ncol = length(beta))

# BEGIN THE SIMULATION STUDY
for (i in 1:Nsim) {
  current_data <- within(bwt, {normwt <- simdata[[i]]})

  # if (i %% 100 == 0) print(i)
  ybar <- mean(current_data$normwt)
  y_clogg <- p / (p + m) * ybar + m / (p + m) * current_data$normwt
  y_dy <- p / (p + m) * 0.5 + m / (p + m) * current_data$normwt
  
  ml_fit <- glm(normwt ~ age + racewhite + smoke + ptl + ht + loglwt, family = binomial, data = current_data)
  br_fit <- update(ml_fit, method = "brglmFit", type = "AS_mean", data = current_data)
  mbr_fit <- update(ml_fit, method = "brglmFit", type = "AS_median", data = current_data)
  sep_fit <- update(ml_fit, method = "detect_separation")
  clogg_fit <- glm(y_clogg ~ age + racewhite + smoke + ptl + ht + loglwt, family = binomial, data = current_data)
  dy_fit <- glm(y_dy ~ age + racewhite + smoke + ptl + ht + loglwt, family = binomial, data = current_data)
  
  # Summaries
  sum_ml <- summary(ml_fit)
  sum_brmean <- summary(br_fit)
  sum_clogg <- summary(clogg_fit)
  sum_brmedian <- summary(mbr_fit)
  sum_dy <- summary(dy_fit)

  # Estimates & std
  ml[i, ] <- sum_ml$coef[, 1]
  ml_se[i, ] <- sum_ml$coef[, 2]

  br[i, ] <- sum_brmean$coef[, 1]
  br_se[i, ] <- sum_brmean$coef[, 2]

  clogg[i, ] <- sum_clogg$coef[, 1]
  clogg_se[i, ] <- sum_clogg$coef[, 2]

  mbr[i, ] <- sum_brmedian$coef[, 1]
  mbr_se[i, ] <- sum_brmedian$coef[, 2]

  dy[i, ] <- sum_dy$coef[, 1]
  dy_se[i, ] <- sum_dy$coef[, 2]

  separation[i, ] <- sep_fit$coef
}

ml.inc <- apply(separation, 1, function(b) all(b == 0))

## BIAS in beta parameterization
bias.beta <- data.frame(
  ml = colMeans(ml[ml.inc, ]),
  br = colMeans(br),
  mbr = colMeans(mbr),
  clogg = colMeans(clogg),
  dy = colMeans(dy)
) - beta

## MSE in beta parameterization
mse.beta <- data.frame(
  ml = rowMeans((t(ml[ml.inc, ]) - beta)^2),
  br = rowMeans((t(br) - beta)^2),
  mbr = rowMeans((t(mbr) - beta)^2),
  clogg = rowMeans((t(clogg) - beta)^2),
  dy = rowMeans((t(dy) - beta)^2)
)

## MAE in beta parameterization
mae.beta <- data.frame(
  ml = rowMeans(abs(t(ml[ml.inc, ]) - beta)),
  br = rowMeans(abs(t(br) - beta)),
  mbr = rowMeans(abs(t(mbr) - beta)),
  clogg = rowMeans(abs(t(clogg) - beta)),
  dy = rowMeans(abs(t(dy) - beta))
)
save(list = c("bias.beta", "mse.beta", "mae.beta"),file = "birthweight_sim.RData")
```

For convenience, we store the results in the file 
[`birthweight_sim.RData`](https://github.com/tommasorigon/logistic-bias-reduction/blob/main/BIRTHWEIGHT/birthweight_sim.RData),
which can be loaded directly; refer to
[birthweight.Rmd](https://raw.githubusercontent.com/tommasorigon/logistic-bias-reduction/main/BIRTHWEIGHT/birthweight.Rmd),
for a complete illustration of the code adapted from @Kosmidis2020.

```{r report,echo=T,eval=T}
load("birthweight_sim.RData")
```

```{r reshalpe, echo=F}
ord = c("ml", "dy", "clogg", "br", "mbr")
bias.beta = bias.beta[,ord]
mse.beta = mse.beta[,ord]
colnames(bias.beta) <- colnames(mse.beta) <-  c("MLE", "Diaconis-Ylvisaker", "@Clogg1991",  "@Firth1993", "@Pagui2017")
```

## Bias

```{r bias,echo=F}
kable(t(bias.beta), digits = 2, caption = "Bias")
```

## RMSE

```{r rmse,echo=F}
kable(t(sqrt(mse.beta)), digits = 2, caption = "RMSE")
```

# References
