---
title: "high-dimensional synthetic example"
author: "Tommaso Rigon and Emanuele Aliverti"
output: html_document
bibliography: ["../biblio.bib"]
---

```{r setup, include=FALSE}
library(knitr)
library(ggplot2)
```

# Simulation studies

The purpose of this study is to investigate the behavior of the proposed estimator 
in high dimensional and computationally challenging scenarios, and compare its performance with
standard maximum likelihood and @Firth1993.

We focus on an example inspired by the Appendix D of @Sur2019 and the Supplementary Materials of @Kosmidis2021, 
focusing on a setting with $n=1000$ observations from a logistic regression model with
$p=200$, and coefficients divided in $5$ blocks of $40$ coefficients with values 
set as `r c(3,1.5,0, -1.5,-3)`.

```{r,echo=T}
set.seed(1991)
n <- 1000
p <- 200
b0 = c(3,1.5,0, -1.5,-3)
beta = rep(b0,each = p/5)
X <- matrix(rnorm(n * (p), 0, sqrt(1 / n)), n, p)
y <- rbinom(n, 1, plogis(X %*% beta))
fit_mle <- glm(y ~ X - 1, family = binomial("logit"))
```


Recalling that penalized likelihood optimization under the proposed Diaconis-Ylvisaker conjugate prior 
induces a binomial likelihood with pseudo-counts, we can rely on different available optimization
 methods for logistic regression models. 
We found that quasi-Newton methods have better numerical performance; refer to @Nocedal2006 for
additional details.
A practical implementation for logistic regression optimization via L-BFGS is provided
in the function `fastLR` available in the package `RcppNumerical`.
We compare estimates and elapsed time for a single estimation.
Analysis are conducted on  a 2020 Macbook Pro with M1 processor 
(`aarch64-apple-darwin20`)  running R 4.1.1 linked with `openblas`. 
For more details on computational performance refer to the file [`compare_timing.r`](https://raw.githubusercontent.com/tommasorigon/logistic-bias-reduction/main/HIGH-DIMENSIONAL-SYNTHETIC/compare_timing.r),
where we compare the elapsed timing with and without classical BLAS libraries via `microbenchmark`.


```{r run,echo=T,warning=F, eval=T}
library(brglm2)
m <- nrow(X)
y_dy <- p / (p + m) * 0.5 + m / (p + m) * y


library(RcppNumerical)
t0 <- Sys.time()

# DY ESTIMATE
fit_fast_dy <- fastLR(X, y_dy)
t1 <- Sys.time()
elapsed_fast_dy <- t1 - t0

# FIRTH (1993)
t0 <- Sys.time()
fit_firth <- brglm_fit(X,y,
  family = binomial("logit"),
  control = list(type = "AS_mean")
)
t1 <- Sys.time()
elapsed_firth <- t1 - t0
```


```{r print-r,echo=F,eval=F}
tt = c( elapsed_fast_dy, elapsed_firth)
names(tt) = c("DY - fast implementation", "@Firth1993")
kable(tt,digits = 3,format = "markdown")
```


```{r, echo=F,warning=F,fig.height=3,fig.width=12,fig.align='center'}
cc = list("MLE" = coef(fit_mle), "Firth" = coef(fit_firth), 
          "DY" = fit_fast_dy$coefficients)
df_list = reshape2::melt(cc)
df_list$x=rep(1:p, length(cc))
df_list$b0 = rep(beta,length(cc))

df_list$L1 = ordered(factor(df_list$L1,levels = c("MLE", "DY", "Clogg", "Firth"), labels = 
         c("Maximum-Likelihood","Diaconis-Ylvisaker",  "Clogg (1991)", "Firth (1993)")))


df_seg = data.frame(matrix(c(0,40,41,80,81,120,121,160,161,200),ncol=2,byrow = T),y=unique(beta))

pl = ggplot(df_list) + 
  geom_point(aes(x,value), color = "gray50") + 
  geom_segment(data=df_seg, aes(x= X1, xend = X2, y = y, yend=y),size = 1.4, color = "black")+
  geom_vline(xintercept = seq(40,160,by=40), lty = 3)+
  facet_wrap(~L1,nrow = 1) + 
  theme_bw() + xlab("") + ylab("Estimated coefficients")
ggsave(pl, file = "figs/coef.png", width = 12,height = 3)
include_graphics("figs/coef.png")
```


We evalutate the frequency properties of
different estimators in terms of bias and RMSE, across 5000 replications of this scenario.
Results are stored in the file `sur-candes.RData` and can be reproduced running
the script
[`sur-candes.R`](https://raw.githubusercontent.com/tommasorigon/logistic-bias-reduction/main/SIMULATIONS/sur-candes.R)
(takes roughly 4 hours).
```{r, echo=F,warning=F,message=FALSE,fig.height=3,fig.width=12,fig.align='center'}
load("sur-candes.RData")
rmse.beta = sqrt(mse.beta)
bias.beta$x = 1:NROW(bias.beta)
rmse.beta$x = 1:NROW(rmse.beta)
# mae.beta$x = 1:NROW(mae.beta)
df = reshape2::melt(list("Bias" = bias.beta, "RMSE" = rmse.beta), id.var = "x")
df = subset(df, variable != "clogg")
df$variable = factor(df$variable, levels = c("ml", "dy",  "br"),
                     labels= c("Maximum\nlikelihood", "Diaconis\nYlvisaker",  "Firth (1993)"),ord=T)

df$xl = cut(df$x,breaks = seq(0,p,by=40), labels = paste0("beta==",c('3','3/2','0','-3/2','-3')))
line_df = subset(df, L1 == "Bias")
line_df = do.call(rbind,by(line_df,line_df$xl, head,1))
line_df$value = 0
library(ggplot2)
pl = ggplot(df) +
  geom_jitter(aes(y = value, x = variable,  group = variable), alpha = .5) +
  geom_boxplot(aes(y = value, x = variable,  group = variable), alpha = .8, color = "gray50") +
  # facet_wrap(~L1 + xl, scales = "free") +
   geom_hline(data = line_df, aes(yintercept=0), col = "gray50", lty = 3)+
  facet_grid(rows=vars(L1), cols = vars(xl), scales = "free",labeller = label_parsed) +
  theme_bw(base_size = 12) + xlab("") + ylab("") + 
  scale_fill_manual(values = c("black", "grey25", "grey75", "white"))+
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60,hjust = 1,vjust = 1),
        strip.text = element_text(size=12)
        )
ggsave(pl, file = "figs/boxpl-1.png",  width = 11,height = 5)
include_graphics("figs/boxpl-1.png")
```

```{r paper-fig,eval=F,echo=F}
# EPS format
pl = ggplot(df) +
  geom_boxplot(aes(y = value, x = variable,  group = variable), color = "gray50") +
  # geom_jitter(aes(y = value, x = variable,  group = variable), alpha = .2, color = "gray") +
  # facet_wrap(~L1 + xl, scales = "free") +
   geom_hline(data = line_df, aes(yintercept=0), col = "gray50", lty = 3)+
  facet_grid(rows=vars(L1), cols = vars(xl), scales = "free",labeller = label_parsed) +
  theme_bw(base_size = 14) + xlab("") + ylab("") + 
  scale_fill_manual(values = c("black", "grey25", "grey75", "white"))+
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60,hjust = 1,vjust = 1),
        strip.text = element_text(size=16)
        )
# pl_min = pl + theme_minimal() + 
#   theme(legend.position = "none",
#         axis.text.x = element_text(angle = 60,hjust = 1,vjust = 1),
#         strip.text = element_text(size=16)
#         ) 
#2 ggsave(pl, file = "figs/boxplot.pdf",  width = 11,height = 5)
# ggsave(pl, file = "figs/boxplot.eps",  width = 11,height = 5)
```



# References